# Phase 7.2: Workflow State Management - Research

**Researched:** 2026-02-01
**Domain:** Workflow execution state management, thread-safe data structures, template resolution
**Confidence:** HIGH

## Summary

This research analyzes the current workflow state architecture to inform the creation of a unified `WorkflowDataStore` class. The codebase currently has two separate state structures:

1. **WorkflowState** (`coordinator/WorkflowState.kt`) - Immutable state machine for orchestration tracking (phase, active/completed/failed nodes, dataRegistry keyed by UUID)
2. **WorkflowExecutionContext** (`environment/WorkflowExecutionContext.kt`) - Mutable execution context with dataRegistry keyed by String (node name)

These must be unified into a single `WorkflowDataStore` with sections for trigger context, step outputs, variables, and loop contexts. The unification requires updating the template resolution system to support new path prefixes (`trigger.`, `steps.`, `variables.`, `loops.`) and creating typed `NodeOutput` sealed interface variants.

**Primary recommendation:** Create `WorkflowDataStore` as a concrete class with ConcurrentHashMap-backed sections, typed NodeOutput sealed interface, and update InputResolverService to resolve against the new structure.

## Current State Analysis

### WorkflowState (coordinator/WorkflowState.kt)

**Purpose:** Immutable state machine tracking orchestration progress

**Fields:**
| Field | Type | Purpose |
|-------|------|---------|
| `phase` | `WorkflowExecutionPhase` | INITIALIZING, EXECUTING_NODES, COMPLETED, FAILED |
| `activeNodes` | `Set<UUID>` | Currently executing node IDs |
| `completedNodes` | `Set<UUID>` | Finished node IDs |
| `failedNodes` | `Set<UUID>` | Failed node IDs |
| `dataRegistry` | `Map<UUID, Any?>` | Node outputs keyed by UUID |

**Key Methods:**
- `isTerminal()` - Checks COMPLETED or FAILED
- `hasActiveNodes()` - Checks active set not empty
- `getNodeOutput(nodeId: UUID)` - Retrieves output by UUID

**State Events (sealed interface StateEvent):**
- `NodesReady(nodeIds: Set<UUID>)`
- `NodeCompleted(nodeId: UUID, output: Any?)`
- `NodeFailed(nodeId: UUID, error: String)`
- `AllNodesCompleted`
- `WorkflowFailed`

**Files Using WorkflowState:** 6 files
- `WorkflowCoordinationService.kt` - Returns from `executeWorkflowWithCoordinator()`
- `WorkflowGraphCoordinationService.kt` - Creates, transitions, returns final state
- `WorkflowOrchestrationService.kt` - Receives from activity, checks phase
- `WorkflowCoordination.kt` - Interface return type
- `StateTransition.kt` - Pure transition logic
- `WorkflowState.kt` - Definition

### WorkflowExecutionContext (environment/WorkflowExecutionContext.kt)

**Purpose:** Mutable execution context separating control plane (metadata) from data plane (outputs)

**Fields:**
| Field | Type | Purpose |
|-------|------|---------|
| `workflowExecutionId` | `UUID` | Execution record ID |
| `workspaceId` | `UUID` | Multi-tenant workspace context |
| `metadata` | `Map<String, Any?>` | Workflow-level orchestration metadata |
| `dataRegistry` | `MutableMap<String, NodeExecutionData>` | Node outputs keyed by name |

**Files Using WorkflowExecutionContext:** 20 files
- All node config files (11 files) - Receive in `execute()` method
- `WorkflowNodeInputResolverService.kt` - Resolves templates against dataRegistry
- `WorkflowCoordinationService.kt` - Creates context, populates registry
- `WorkflowNode.kt` - Passes to config.execute()
- `NodeServiceProvider.kt` - Interface signature
- Test files (5 files)

### NodeExecutionData (environment/NodeExecutionData.kt)

**Purpose:** Immutable record of a node's execution output

**Fields:**
| Field | Type | Purpose |
|-------|------|---------|
| `nodeId` | `UUID` | Executed node ID |
| `nodeName` | `String` | Name for template references |
| `status` | `WorkflowStatus` | COMPLETED, FAILED, SKIPPED |
| `output` | `Map<String, Any?>?` | Action outputs (null if failed) |
| `error` | `String?` | Error message if failed |
| `executedAt` | `Instant` | Completion timestamp |

### Field Mapping for Unification

| Current Location | Current Type | New DataStore Location | New Type |
|------------------|--------------|------------------------|----------|
| `WorkflowState.phase` | `WorkflowExecutionPhase` | Keep in orchestrator | N/A (not datastore concern) |
| `WorkflowState.activeNodes` | `Set<UUID>` | Keep in orchestrator | N/A |
| `WorkflowState.completedNodes` | `Set<UUID>` | Keep in orchestrator | N/A |
| `WorkflowState.failedNodes` | `Set<UUID>` | Keep in orchestrator | N/A |
| `WorkflowState.dataRegistry` | `Map<UUID, Any?>` | Remove (unified into steps) | N/A |
| `WorkflowExecutionContext.workflowExecutionId` | `UUID` | `dataStore.metadata.executionId` | `UUID` |
| `WorkflowExecutionContext.workspaceId` | `UUID` | `dataStore.metadata.workspaceId` | `UUID` |
| `WorkflowExecutionContext.metadata` | `Map<String, Any?>` | `dataStore.metadata` | Typed class |
| `WorkflowExecutionContext.dataRegistry` | `MutableMap<String, NodeExecutionData>` | `dataStore.steps` | `ConcurrentHashMap<String, StepOutput>` |
| N/A | N/A | `dataStore.trigger` | `TriggerContext` |
| N/A | N/A | `dataStore.variables` | `ConcurrentHashMap<String, Any?>` |
| N/A | N/A | `dataStore.loops` | `ConcurrentHashMap<String, LoopContext>` |

## Template Resolution System

### Current Resolution Mechanism

**WorkflowNodeTemplateParserService** parses `{{ path.to.data }}` syntax:
- Regex: `\{\{\s*([a-zA-Z0-9_.]+)\s*\}\}`
- Returns `ParsedTemplate` with path segments
- Supports embedded templates: `"Hello {{ steps.user.name }}"`

**WorkflowNodeInputResolverService** resolves parsed templates:
- First segment MUST be `steps` (only supported in Phase 4.1)
- Second segment is node name
- Looks up `context.dataRegistry[nodeName]`
- Traverses remaining path through output map

**Current Path Syntax:**
```
{{ steps.nodeName.output.field }}
     ^     ^        ^      ^
     |     |        |      +-- Optional: nested property
     |     |        +-- Optional: "output" keyword (skipped if present)
     |     +-- Node name (key in dataRegistry)
     +-- Required: must be "steps"
```

### Required Path Syntax Changes (from CONTEXT.md)

| Path Type | Old Syntax | New Syntax | Example |
|-----------|------------|------------|---------|
| Step output | `{{ steps.name.output.field }}` | `{{ steps.name.output.field }}` | `{{ steps.fetchUser.output.email }}` |
| Trigger data | N/A | `{{ trigger.entity.id }}` | `{{ trigger.entity.payload.name }}` |
| Variables | N/A | `{{ variables.counter }}` | `{{ variables.lastProcessedId }}` |
| Loop context | N/A | `{{ loops.loopName.currentItem }}` | `{{ loops.processUsers.currentItem.email }}` |

### Changes Needed in WorkflowNodeInputResolverService

1. **Update `resolveTemplatePath()` to handle multiple root segments:**
   - `steps` - Existing, lookup in steps map
   - `trigger` - New, lookup in trigger context
   - `variables` - New, lookup in variables map
   - `loops` - New, lookup in loop contexts map

2. **Update context parameter:** Change from `WorkflowExecutionContext` to `WorkflowDataStore`

3. **Add typed getters:** Methods like `getTrigger()`, `getStepOutput(name)` per CONTEXT.md

4. **Fail fast on resolution:** Invalid paths throw exception at resolution time (CONTEXT.md decision)

## Node Output Patterns

### Current Node Execute Return Types

All nodes return `Map<String, Any?>` from `execute()`:

| Node Type | Return Keys | Example |
|-----------|-------------|---------|
| CREATE_ENTITY | `entityId`, `entityTypeId`, `payload` | `mapOf("entityId" to uuid, "entityTypeId" to uuid, "payload" to map)` |
| UPDATE_ENTITY | `entityId`, `updated`, `payload` | `mapOf("entityId" to uuid, "updated" to true, "payload" to map)` |
| DELETE_ENTITY | `entityId`, `deleted`, `impactedEntities` | `mapOf("entityId" to uuid, "deleted" to true, "impactedEntities" to 0)` |
| QUERY_ENTITY | `entities`, `totalCount`, `hasMore` | (Not implemented yet) |
| HTTP_REQUEST | `statusCode`, `headers`, `body`, `url`, `method` | `mapOf("statusCode" to 200, "headers" to map, "body" to string)` |
| CONDITION | `conditionResult` | `mapOf("conditionResult" to true)` |

### NodeOutput Sealed Interface Design (from CONTEXT.md)

```kotlin
sealed interface NodeOutput {
    // Marker interface for all typed outputs
}

data class CreateEntityOutput(
    val entityId: UUID,
    val entityTypeId: UUID,
    val payload: Map<UUID, Any?>
) : NodeOutput

data class UpdateEntityOutput(
    val entityId: UUID,
    val updated: Boolean,
    val payload: Map<UUID, Any?>
) : NodeOutput

data class DeleteEntityOutput(
    val entityId: UUID,
    val deleted: Boolean,
    val impactedEntities: Int
) : NodeOutput

data class QueryEntityOutput(
    val entities: List<Entity>,
    val totalCount: Int,
    val hasMore: Boolean
) : NodeOutput

data class HttpResponseOutput(
    val statusCode: Int,
    val headers: Map<String, String>,
    val body: String?,
    val url: String,
    val method: String
) : NodeOutput {
    val success: Boolean get() = statusCode in 200..299
}

data class ConditionOutput(
    val result: Boolean,
    val evaluatedExpression: String
) : NodeOutput
```

### Output Type Mapping by Action

| WorkflowActionType | NodeOutput Class |
|--------------------|------------------|
| `CREATE_ENTITY` | `CreateEntityOutput` |
| `UPDATE_ENTITY` | `UpdateEntityOutput` |
| `DELETE_ENTITY` | `DeleteEntityOutput` |
| `QUERY_ENTITY` | `QueryEntityOutput` |
| `HTTP_REQUEST` | `HttpResponseOutput` |
| `LINK_ENTITY` | `LinkEntityOutput` (TBD) |
| `INTEGRATION_REQUEST` | `IntegrationOutput` (TBD) |
| `SET_ENVIRONMENT_VARIABLE` | `SetVariableOutput` (TBD) |
| `MAP_DATA` | `MapDataOutput` (TBD) |
| `CONDITION` (control) | `ConditionOutput` |

## Integration Points

### Service Dependencies

```
WorkflowOrchestrationService (Temporal workflow)
    |
    v
WorkflowCoordinationService (Temporal activity)
    |
    +-> WorkflowGraphCoordinationService (DAG execution)
    |       |
    |       +-> WorkflowGraphQueueManagementService (node scheduling)
    |       +-> WorkflowGraphTopologicalSorterService (ordering)
    |       +-> WorkflowGraphValidationService (DAG validation)
    |
    +-> WorkflowNodeInputResolverService (template resolution)
    |       |
    |       +-> WorkflowNodeTemplateParserService (parsing)
    |
    +-> WorkflowNode.execute() (polymorphic dispatch)
            |
            +-> NodeServiceProvider (Spring service access)
```

### Where DataStore Should Be Created/Passed/Consumed

| Location | Current | After Unification |
|----------|---------|-------------------|
| **Created** | `WorkflowCoordinationService.executeWorkflowWithCoordinator()` creates `WorkflowExecutionContext` | Same location creates `WorkflowDataStore` |
| **Passed** | Context passed to `executeNode()` then to `node.execute()` | DataStore passed through same path |
| **Written** | `executeAction()` writes to `context.dataRegistry[nodeName]` | Coordinator calls `dataStore.setStepOutput(name, output)` |
| **Read** | `InputResolverService.resolve()` reads from `context.dataRegistry` | Same service reads from `dataStore.getStepOutput(name)` |

### Method Signatures That Need Updates

**WorkflowNodeConfig.execute():**
```kotlin
// Current
fun execute(context: WorkflowExecutionContext, inputs: JsonObject, services: NodeServiceProvider): JsonObject

// After (nodes return typed output, coordinator writes)
fun execute(dataStore: WorkflowDataStore, inputs: JsonObject, services: NodeServiceProvider): NodeOutput
```

**WorkflowNode.execute():**
```kotlin
// Current
fun execute(context: WorkflowExecutionContext, inputs: JsonObject, services: NodeServiceProvider): JsonObject

// After
fun execute(dataStore: WorkflowDataStore, inputs: JsonObject, services: NodeServiceProvider): NodeOutput
```

**WorkflowNodeInputResolverService.resolve():**
```kotlin
// Current
fun resolve(templateOrValue: Any?, context: WorkflowExecutionContext): Any?

// After
fun resolve(templateOrValue: Any?, dataStore: WorkflowDataStore): Any?
```

**WorkflowNodeInputResolverService.resolveAll():**
```kotlin
// Current
fun resolveAll(config: Map<String, Any?>, context: WorkflowExecutionContext): Map<String, Any?>

// After
fun resolveAll(config: Map<String, Any?>, dataStore: WorkflowDataStore): Map<String, Any?>
```

## Thread Safety Analysis

### Parallel Execution Patterns

The DAG coordinator executes nodes in parallel batches:
```kotlin
// WorkflowGraphCoordinationService.executeWorkflow()
while (workflowGraphQueueManagementService.hasMoreWork()) {
    val readyNodes = workflowGraphQueueManagementService.getReadyNodes()

    // Execute batch in parallel (caller handles Temporal Async/Promise)
    val results = nodeExecutor(readyNodes)  // Parallel execution here

    // Mark each node completed
    for ((nodeId, output) in results) {
        state = StateTransition.apply(state, NodeCompleted(nodeId, output))
    }
}
```

**Current Comment in WorkflowCoordinationService:**
```kotlin
// Todo: Parallel execution is just glorified sequential execution for now
// Can use Temporal child workflows for true parallel execution
```

Currently, the `nodeExecutor` lambda maps over `readyNodes` sequentially with `.map {}`. True parallelism is deferred but the architecture should support it.

### Concurrent Access Points

| Data Section | Write Frequency | Read Frequency | Concurrency Pattern |
|--------------|-----------------|----------------|---------------------|
| `trigger` | Once (at start) | Many | Write-once, then read-only |
| `steps` | Once per node | Many | Write-once per key, concurrent reads |
| `variables` | Multiple times | Many | Last-write-wins, concurrent access |
| `loops` | Per loop iteration | During loop | Branch-scoped, minimal contention |
| `metadata` | Once (at start) | Many | Write-once, then read-only |

### Locking Requirements (from CONTEXT.md)

1. **ConcurrentHashMap for steps, variables, loops** - Handles concurrent reads and fine-grained writes
2. **Write-once enforcement for steps** - Throw `IllegalStateException` if step output already exists
3. **Branch-scoped loop contexts** - Each parallel branch gets its own LoopContext entry keyed by branch/loop ID
4. **Last-write-wins for variables** - ConcurrentHashMap.put() semantics

### Proposed WorkflowDataStore Thread Safety

```kotlin
class WorkflowDataStore(
    private val metadata: WorkflowMetadata  // Immutable after construction
) {
    // Write-once trigger context
    @Volatile
    private var _trigger: TriggerContext? = null

    // Thread-safe steps (write-once per key)
    private val steps = ConcurrentHashMap<String, StepOutput>()

    // Thread-safe variables (last-write-wins)
    private val variables = ConcurrentHashMap<String, Any?>()

    // Thread-safe loop contexts (branch-scoped)
    private val loops = ConcurrentHashMap<String, LoopContext>()

    fun setTrigger(trigger: TriggerContext) {
        if (_trigger != null) throw IllegalStateException("Trigger already set")
        _trigger = trigger
    }

    fun setStepOutput(name: String, output: StepOutput) {
        val existing = steps.putIfAbsent(name, output)
        if (existing != null) {
            throw IllegalStateException("Step output already exists for: $name")
        }
    }

    fun setVariable(name: String, value: Any?) {
        variables[name] = value  // Last-write-wins
    }

    fun setLoopContext(loopId: String, context: LoopContext) {
        loops[loopId] = context
    }
}
```

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Thread-safe maps | Custom synchronized wrappers | `ConcurrentHashMap` | Java stdlib, battle-tested, excellent concurrent performance |
| Sealed class serialization | Custom JSON handling | Jackson sealed class support | Already used for other sealed interfaces in codebase |
| Template parsing | Custom lexer/parser | Existing `WorkflowNodeTemplateParserService` | Already implemented and tested |
| Expression evaluation | Custom evaluator | Existing `WorkflowNodeExpressionParserService` | Already implemented for CONDITION |

## Common Pitfalls

### Pitfall 1: Forgetting to Update All Node Execute Signatures
**What goes wrong:** Node configs still return `Map<String, Any?>` instead of typed `NodeOutput`
**Why it happens:** 11 node config files need updating, easy to miss one
**How to avoid:** Update sealed interface first, let compiler errors guide updates
**Warning signs:** ClassCastException at runtime, tests fail

### Pitfall 2: Breaking Template Resolution Backward Compatibility
**What goes wrong:** Existing `{{ steps.name.output.field }}` paths stop working
**Why it happens:** Path resolution logic changes
**How to avoid:** Keep `output` as optional segment (current behavior), add new prefixes
**Warning signs:** Template resolution returns null where it previously worked

### Pitfall 3: Race Condition in Write-Once Enforcement
**What goes wrong:** Two parallel nodes write to same step name
**Why it happens:** `check-then-act` without atomic operation
**How to avoid:** Use `putIfAbsent()` and check return value
**Warning signs:** Inconsistent step outputs, lost data

### Pitfall 4: Mixing Mutable and Immutable Semantics
**What goes wrong:** External code modifies StepOutput after storage
**Why it happens:** Data classes with mutable collections
**How to avoid:** Ensure NodeOutput subtypes use immutable collections, deep copy on storage
**Warning signs:** Mysterious data changes, non-deterministic behavior

### Pitfall 5: Not Handling Missing Trigger in Input Resolution
**What goes wrong:** `{{ trigger.entity.id }}` throws NPE when trigger not set
**Why it happens:** Trigger set asynchronously, template resolved before set
**How to avoid:** Explicit null check with clear error message, or validate trigger is set before resolution
**Warning signs:** NPE in template resolution

## Code Examples

### WorkflowDataStore Creation

```kotlin
// Source: Pattern based on existing WorkflowExecutionContext creation
// In WorkflowCoordinationService.executeWorkflowWithCoordinator()

val metadata = WorkflowMetadata(
    executionId = workflowExecutionId,
    workspaceId = workspaceId,
    workflowDefinitionId = workflowDefinitionId,
    version = workflowVersion,
    startedAt = Instant.now()
)

val dataStore = WorkflowDataStore(metadata)

// Set trigger context based on how workflow was started
dataStore.setTrigger(TriggerContext.EntityEvent(
    eventType = EntityEventType.CREATED,
    entity = triggerEntity,
    previousEntity = null
))
```

### StepOutput Storage (Coordinator Writes)

```kotlin
// Source: Pattern based on existing executeAction() in WorkflowCoordinationService
// After node.execute() returns NodeOutput:

val nodeOutput: NodeOutput = node.execute(dataStore, resolvedInputs, nodeServiceProvider)

val stepOutput = StepOutput(
    nodeId = node.id,
    nodeName = node.name,
    status = WorkflowStatus.COMPLETED,
    output = nodeOutput,
    executedAt = Instant.now(),
    durationMs = System.currentTimeMillis() - startTime
)

dataStore.setStepOutput(node.name, stepOutput)
```

### Template Resolution with Multiple Prefixes

```kotlin
// Source: Extension of existing WorkflowNodeInputResolverService.resolveTemplatePath()

private fun resolveTemplatePath(path: List<String>, dataStore: WorkflowDataStore): Any? {
    if (path.isEmpty()) throw IllegalArgumentException("Empty template path")

    val rootSegment = path[0]

    return when (rootSegment) {
        "steps" -> resolveStepsPath(path.drop(1), dataStore)
        "trigger" -> resolveTriggerPath(path.drop(1), dataStore)
        "variables" -> resolveVariablesPath(path.drop(1), dataStore)
        "loops" -> resolveLoopsPath(path.drop(1), dataStore)
        else -> throw IllegalArgumentException(
            "Invalid root segment '$rootSegment'. Must be: steps, trigger, variables, loops"
        )
    }
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Two separate state classes | Single WorkflowDataStore | Phase 7.2 | Unified state, simpler mental model |
| Untyped `Map<String, Any?>` outputs | Typed `NodeOutput` sealed interface | Phase 7.2 | Type-safe outputs, IDE support |
| Only `steps` prefix | Multiple prefixes (trigger, variables, loops) | Phase 7.2 | Full data access from templates |

## Open Questions

### 1. NodeOutput Property Access for Template Resolution

**What we know:** NodeOutput is a sealed interface with typed data classes
**What's unclear:** How to traverse NodeOutput properties in template resolution (`{{ steps.name.output.entityId }}`)
**Recommendation:** Use Kotlin reflection to get property value by name, or add `toMap(): Map<String, Any?>` method to NodeOutput interface

### 2. TriggerContext Population Timing

**What we know:** Trigger context must be set before any template resolution
**What's unclear:** When exactly is trigger data available for different trigger types (webhook vs entity event vs schedule)
**Recommendation:** Set trigger in orchestration service before calling coordination activity, validate trigger exists before first node execution

### 3. Metadata Scope

**What we know:** CONTEXT.md mentions "full observability metadata" including trace IDs, parent workflow info
**What's unclear:** Exact fields needed, whether OpenTelemetry integration is in scope
**Recommendation:** Start with minimal metadata (executionId, workspaceId, workflowDefinitionId, version, startedAt), add observability fields as needed

## Implementation Recommendations

### Suggested Plan Breakdown

1. **07.2-01: WorkflowDataStore class and StepOutput**
   - Create WorkflowDataStore with ConcurrentHashMap sections
   - Create StepOutput data class (replaces NodeExecutionData)
   - Create WorkflowMetadata data class
   - Thread-safe setStepOutput() with write-once enforcement
   - Unit tests for concurrency

2. **07.2-02: NodeOutput sealed interface**
   - Create NodeOutput sealed interface
   - Create typed output classes (CreateEntityOutput, HttpResponseOutput, etc.)
   - Add property access method for template resolution
   - Unit tests

3. **07.2-03: TriggerContext sealed interface**
   - Create TriggerContext sealed interface with EntityEvent, Webhook, Schedule, Function
   - Add setTrigger() to WorkflowDataStore with write-once
   - Unit tests

4. **07.2-04: Update InputResolverService**
   - Change parameter from WorkflowExecutionContext to WorkflowDataStore
   - Add support for trigger, variables, loops prefixes
   - Update resolveTemplatePath() for NodeOutput property access
   - Maintain backward compatibility for steps prefix
   - Unit tests

5. **07.2-05: Update node configs to return NodeOutput**
   - Update WorkflowNodeConfig.execute() signature
   - Update all 11 node config implementations
   - Update WorkflowNode.execute()
   - Unit tests

6. **07.2-06: Integration and removal**
   - Update WorkflowCoordinationService to use WorkflowDataStore
   - Coordinator writes to dataStore after node returns
   - Remove WorkflowState.dataRegistry usage
   - Remove WorkflowExecutionContext
   - Integration tests

### Risk Areas

1. **Breaking existing tests** - 5+ test files use WorkflowExecutionContext directly
2. **Node config signature changes** - 11 files need coordinated updates
3. **Template resolution regression** - Must maintain backward compatibility
4. **Temporal workflow determinism** - DataStore must be serializable for replay

### Dependencies Between Tasks

```
07.2-01 (WorkflowDataStore)
    |
    +-> 07.2-02 (NodeOutput) ----+
    |                             |
    +-> 07.2-03 (TriggerContext) |
    |                             |
    +-> 07.2-04 (InputResolver) <-+
    |
    +-> 07.2-05 (Node configs) <-- 07.2-02
    |
    v
07.2-06 (Integration)
```

## Sources

### Primary (HIGH confidence)
- `/home/jared/dev/riven/core/src/main/kotlin/riven/core/models/workflow/engine/coordinator/WorkflowState.kt` - Current state machine
- `/home/jared/dev/riven/core/src/main/kotlin/riven/core/models/workflow/engine/environment/WorkflowExecutionContext.kt` - Current execution context
- `/home/jared/dev/riven/core/src/main/kotlin/riven/core/service/workflow/state/WorkflowNodeInputResolverService.kt` - Template resolution
- `/home/jared/dev/riven/core/src/main/kotlin/riven/core/service/workflow/engine/coordinator/WorkflowCoordinationService.kt` - Integration point
- `/home/jared/dev/riven/core/.planning/phases/07.2-workflow-state-management/07.2-CONTEXT.md` - User decisions

### Secondary (MEDIUM confidence)
- Kotlin ConcurrentHashMap documentation - Thread safety patterns
- Kotlin sealed interface documentation - Type hierarchy patterns

## Metadata

**Confidence breakdown:**
- Current state analysis: HIGH - Direct code inspection
- Template resolution: HIGH - Working implementation exists
- Node output patterns: HIGH - Code review of all 6 implemented nodes
- Thread safety: MEDIUM - Based on documented patterns, actual parallelism deferred
- Integration points: HIGH - Direct code tracing

**Research date:** 2026-02-01
**Valid until:** 2026-03-01 (30 days - stable domain, internal architecture)
